{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U bitsandbytes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onGnXEVZt4Op",
        "outputId": "92819e23-e6eb-4cf5-dc98-820e409ffbf5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers.utils.quantization_config import BitsAndBytesConfig\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "i0Koy5-WWMej"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "ofnx4keLWORc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Soorya03/Mistral-7b-FashionAssistant\")\n",
        "\n",
        "# Set quantization config for 4-bit\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True, quant_method=\"int8\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXhvO3QpWRpZ",
        "outputId": "70ff85f4-42a0-450b-b4b4-cc495813dace"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quantization configuration\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "# Attempt to load model with 4-bit quantization\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        \"Soorya03/Mistral-7b-FashionAssistant\",\n",
        "        quantization_config=quantization_config,\n",
        "        device_map=\"auto\"  # Automatically map to available devices\n",
        "    )\n",
        "    print(\"Model loaded with 4-bit quantization.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading quantized model: {e}\")\n",
        "\n",
        "    # Try loading the model without quantization\n",
        "    try:\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            \"Soorya03/Mistral-7b-FashionAssistant\",\n",
        "            device_map=\"cpu\",  # Load on CPU\n",
        "            torch_dtype=torch.float32\n",
        "        )\n",
        "        print(\"Model loaded on CPU with full precision.\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Error loading model on CPU: {e2}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or4o4tPdWV6g",
        "outputId": "d9e826e3-0956-4202-d3dc-cbe178468a35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded with 4-bit quantization.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input text for the model\n",
        "input_text = input(\"Enter your prompt: \")\n",
        "\n",
        "# Tokenize\n",
        "encoding = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "input_ids = encoding[\"input_ids\"]\n",
        "attention_mask = encoding[\"attention_mask\"]\n",
        "\n",
        "input_ids = input_ids.to(model.device)\n",
        "attention_mask = attention_mask.to(model.device)\n",
        "\n",
        "# Generate the output\n",
        "outputs = model.generate(input_ids, max_length=200, attention_mask=attention_mask, pad_token_id=tokenizer.eos_token_id)\n",
        "\n",
        "\n",
        "#print the output text\n",
        "fashion_advice = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(fashion_advice)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHxTnIjJ6v_P",
        "outputId": "7753a404-2079-458f-d0b1-1ff0c4c81931"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: what to wear to a job interview at apple\n",
            "what to wear to a job interview at apple\n",
            "\n",
            "## What to Wear to a Job Interview at Apple\n",
            "\n",
            "Apple is one of the most recognizable and respected companies in the world, and it’s no surprise that they receive a high volume of job applications. If you’re lucky enough to be invited to an interview, it’s important to make a good impression. Here are some tips on what to wear to a job interview at Apple.\n",
            "\n",
            "### Dress for Success\n",
            "\n",
            "Apple is known for its sleek and minimalist aesthetic, so it’s important to dress in a way that reflects this. Avoid anything too flashy or overly casual, and opt for a more professional look. A suit or blazer is always a safe choice, but you can also dress in a more casual way if you feel comfortable doing so. Just make sure that your outfit is clean and well-fitting.\n",
            "\n",
            "### Be Comfortable\n"
          ]
        }
      ]
    }
  ]
}